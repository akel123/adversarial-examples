{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa96d43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow.contrib.slim.nets import inception\n",
    "import tensorflow as tf\n",
    "import matlab.engine\n",
    "from src.config import Config\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imsave\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import IPython.display\n",
    "from utils.sample_attacks.fgsm.attack_fgsm import save_images\n",
    "\n",
    "from src.jpeg_denoise import jpeg\n",
    "from src.fourier_whole_denoise import fourier_whole, get_subdirs\n",
    "from src.pca_whole_denoise import pca_whole\n",
    "from src.pca_blockwise_denoise import pca_blockwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875c9afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(input_dir, batch_shape):\n",
    "    images = np.zeros(batch_shape)\n",
    "    filenames = []\n",
    "    idx = 0\n",
    "    batch_size = batch_shape[0]\n",
    "    for filepath in sorted(tf.gfile.Glob(os.path.join(input_dir, '*.png'))):\n",
    "        with tf.gfile.Open(filepath, \"rb\") as f:\n",
    "            images[idx, :, :, :] = imread(f, mode='RGB').astype(np.float)*2.0/255.0 - 1.0\n",
    "        filenames.append(os.path.basename(filepath))\n",
    "        idx += 1\n",
    "        if idx == batch_size:\n",
    "            yield filenames, images\n",
    "            filenames = []\n",
    "            images = np.zeros(batch_shape)\n",
    "            idx = 0\n",
    "    if idx > 0:\n",
    "        yield filenames, images\n",
    "\n",
    "def show_image(a, fmt='png'):\n",
    "    a = np.uint8((a+1.0)/2.0*255.0)\n",
    "    f = BytesIO()\n",
    "    Image.fromarray(a).save(f, fmt)\n",
    "    IPython.display.display(IPython.display.Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0915e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionModel(object):\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.built = False\n",
    "\n",
    "    def __call__(self, x_input):\n",
    "        \"\"\"Constructs model and return probabilities for given input.\"\"\"\n",
    "        reuse = True if self.built else None\n",
    "        with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "            _, end_points = inception.inception_v3(\n",
    "                            x_input, num_classes=self.num_classes, is_training=False,\n",
    "                            reuse=reuse)\n",
    "        self.built = True\n",
    "        output = end_points['Predictions']\n",
    "        probs = output.op.inputs[0]\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f9155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "slim = tf.contrib.slim \n",
    "# categories = pd.read_csv(\"../project_miscellaneous/nips-2017-defense-against-adversarial-attack/dev_toolkit/dataset/dev_dataset.csv\")\n",
    "categories = pd.read_csv(\"../project_miscellaneous/nips-2017-adversarial-learning-development-set/inputs/categories.csv\")\n",
    "image_width          = 299\n",
    "image_height         = 299\n",
    "checkpoint_path      = \"./inception_v3.ckpt\"\n",
    "tensorflow_master   = ''\n",
    "master               = ''\n",
    "# max_epsilon          = 16.0\n",
    "image_width          = 299\n",
    "image_height         = 299\n",
    "batch_size           = 1\n",
    "# eps = 2.0 * max_epsilon / 255.0\n",
    "batch_shape = [batch_size, image_height, image_width, 3]\n",
    "num_classes = 1001\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR) # so we don't get a bunch of logging info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29da13b",
   "metadata": {},
   "source": [
    "# Attacking images with no defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e49d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir            = './demo/original/'\n",
    "output_dir           = './demo/adversarial/' # currently we're not using the output directory because we're not saving anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4101aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eps = np.append(np.linspace(0, 0.2, 21), 1)\n",
    "all_eps = list(map(lambda x: round(x, 2), all_eps))\n",
    "adv_images_nodefense = dict()\n",
    "for eps in all_eps:\n",
    "    with tf.Graph().as_default():\n",
    "        # Prepare graph\n",
    "        x_input = tf.placeholder(tf.float32, shape=batch_shape)\n",
    "\n",
    "        model = InceptionModel(num_classes)\n",
    "\n",
    "        fgsm = FastGradientMethod(model)\n",
    "        x_adv = fgsm.generate(x_input, eps=eps, clip_min=-1., clip_max=1.)\n",
    "\n",
    "        # Run computation\n",
    "        saver = tf.train.Saver(slim.get_model_variables())\n",
    "        session_creator = tf.train.ChiefSessionCreator(\n",
    "                                scaffold=tf.train.Scaffold(saver=saver),\n",
    "                                checkpoint_filename_with_path=checkpoint_path)\n",
    "\n",
    "        with tf.train.MonitoredSession(session_creator=session_creator) as sess:\n",
    "            filenames, images = next(load_images(input_dir, batch_shape))\n",
    "            adv_images_nodefense[eps] = sess.run(x_adv, feed_dict={x_input: images})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0346074",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes_nodefense = dict()\n",
    "predicted_names_nodefense = dict()\n",
    "with tf.Graph().as_default():\n",
    "    x_input = tf.placeholder(tf.float32, shape=batch_shape)\n",
    "\n",
    "    with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "        _, end_points = inception.inception_v3(x_input, num_classes=num_classes, is_training=False)\n",
    "    \n",
    "    predicted_labels = tf.argmax(end_points['Predictions'], 1)\n",
    "    saver = tf.train.Saver(slim.get_model_variables())\n",
    "    session_creator = tf.train.ChiefSessionCreator(\n",
    "                      scaffold=tf.train.Scaffold(saver=saver),\n",
    "                      checkpoint_filename_with_path=checkpoint_path,\n",
    "                      master=tensorflow_master)\n",
    "\n",
    "    with tf.train.MonitoredSession(session_creator=session_creator) as sess:\n",
    "        for eps in all_eps:\n",
    "            predicted_classes = sess.run(predicted_labels, feed_dict={x_input: images})\n",
    "    #         predicted_classes_nodefense = sess.run(predicted_labels, feed_dict={x_input: nontargeted_images})\n",
    "            predicted_classes_nodefense[eps] = sess.run(predicted_labels, feed_dict={x_input: [adv_images_nodefense[eps]]})\n",
    "\n",
    "            predicted_names_nodefense[eps] = (pd.DataFrame({\"CategoryId\": predicted_classes_nodefense[eps]})\n",
    "                                      .merge(categories, on=\"CategoryId\")[\"CategoryName\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86440e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(np.concatenate([adv_images_nodefense[0], adv_images_nodefense[0.01], adv_images_nodefense[1]], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2daf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_names_nodefense[0])\n",
    "print(predicted_names_nodefense[0.01])\n",
    "print(predicted_names_nodefense[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3678b308",
   "metadata": {},
   "source": [
    "# Attacking with just random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52dde3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eps = np.append(np.linspace(0, 0.2, 21), 1)\n",
    "all_eps = list(map(lambda x: round(x, 2), all_eps))\n",
    "noisy_images = dict()\n",
    "for eps in all_eps:\n",
    "    with tf.Graph().as_default():\n",
    "        x_input = tf.placeholder(tf.float32, shape=batch_shape)\n",
    "        noisy_im = x_input + eps * tf.sign(tf.random_normal(batch_shape))\n",
    "        x_output = tf.clip_by_value(noisy_im, 0.0, 1.0)\n",
    "\n",
    "        with tf.Session(master) as sess:\n",
    "            filenames, images = next(load_images(input_dir, batch_shape))\n",
    "            noisy_images[round(eps, 2)] = sess.run(x_output, feed_dict={x_input: images})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8eea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_clases_noiseattack = dict()\n",
    "predicted_names_noiseattack = dict()\n",
    "with tf.Graph().as_default():\n",
    "    x_input = tf.placeholder(tf.float32, shape=batch_shape)\n",
    "\n",
    "    with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "        _, end_points = inception.inception_v3(x_input, num_classes=num_classes, is_training=False)\n",
    "    \n",
    "    predicted_labels = tf.argmax(end_points['Predictions'], 1)\n",
    "    saver = tf.train.Saver(slim.get_model_variables())\n",
    "    session_creator = tf.train.ChiefSessionCreator(\n",
    "                      scaffold=tf.train.Scaffold(saver=saver),\n",
    "                      checkpoint_filename_with_path=checkpoint_path,\n",
    "                      master=tensorflow_master)\n",
    "\n",
    "    with tf.train.MonitoredSession(session_creator=session_creator) as sess:\n",
    "        for eps in all_eps:\n",
    "            predicted_classes = sess.run(predicted_labels, feed_dict={x_input: images})\n",
    "    #         predicted_clases_noiseattack = sess.run(predicted_labels, feed_dict={x_input: nontargeted_images})\n",
    "            predicted_clases_noiseattack[eps] = sess.run(predicted_labels, feed_dict={x_input: [noisy_images[eps]]})\n",
    "\n",
    "            predicted_names_noiseattack[eps] = (pd.DataFrame({\"CategoryId\": predicted_clases_noiseattack[eps]})\n",
    "                                      .merge(categories, on=\"CategoryId\")[\"CategoryName\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3846214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(np.concatenate([noisy_images[0], noisy_images[0.1], noisy_images[1]], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77568e13",
   "metadata": {},
   "source": [
    "I don't know why the images loses some intensitiy...we'll have to debug this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baa0da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_names_noiseattack[0])\n",
    "print(predicted_names_noiseattack[0.1])\n",
    "print(predicted_names_noiseattack[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e655e8",
   "metadata": {},
   "source": [
    " # Apply JPEG Defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000413ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_base_dir            = './demo'\n",
    "denoise_base_dir           = './'\n",
    "out_images = jpeg(attack_base_dir, denoise_base_dir, 23) # last parameter is quality of compression (1-100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5980cacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename jpg back to png so the network will classify it\n",
    "for out_dir in out_images:\n",
    "    for im in os.listdir(out_dir):\n",
    "        path = out_dir + im\n",
    "        os.rename(path, path.replace('.jpg', '.png'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c89732",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir            = './jpeg_23/demo/original'\n",
    "output_dir           = './demo1/adversarial'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8340933",
   "metadata": {},
   "source": [
    "# Run attack against JPEG images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d652309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eps = np.append(np.linspace(0, 0.2, 21), 1)\n",
    "all_eps = list(map(lambda x: round(x, 2), all_eps))\n",
    "adv_images_jpeg = dict()\n",
    "for eps in all_eps:\n",
    "    with tf.Graph().as_default():\n",
    "        # Prepare graph\n",
    "        x_input = tf.placeholder(tf.float32, shape=batch_shape)\n",
    "\n",
    "        model = InceptionModel(num_classes)\n",
    "\n",
    "        fgsm = FastGradientMethod(model)\n",
    "        x_adv = fgsm.generate(x_input, eps=eps, clip_min=-1., clip_max=1.)\n",
    "\n",
    "        # Run computation\n",
    "        saver = tf.train.Saver(slim.get_model_variables())\n",
    "        session_creator = tf.train.ChiefSessionCreator(\n",
    "                                scaffold=tf.train.Scaffold(saver=saver),\n",
    "                                checkpoint_filename_with_path=checkpoint_path)\n",
    "\n",
    "        with tf.train.MonitoredSession(session_creator=session_creator) as sess:\n",
    "            filenames, images = next(load_images(input_dir, batch_shape))\n",
    "            adv_images_jpeg[eps] = sess.run(x_adv, feed_dict={x_input: images})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b7848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes_jpegdefense = dict()\n",
    "predicted_names_jpegdefense = dict()\n",
    "with tf.Graph().as_default():\n",
    "    x_input = tf.placeholder(tf.float32, shape=batch_shape)\n",
    "\n",
    "    with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "        _, end_points = inception.inception_v3(x_input, num_classes=num_classes, is_training=False)\n",
    "    \n",
    "    predicted_labels = tf.argmax(end_points['Predictions'], 1)\n",
    "    saver = tf.train.Saver(slim.get_model_variables())\n",
    "    session_creator = tf.train.ChiefSessionCreator(\n",
    "                      scaffold=tf.train.Scaffold(saver=saver),\n",
    "                      checkpoint_filename_with_path=checkpoint_path,\n",
    "                      master=tensorflow_master)\n",
    "\n",
    "    with tf.train.MonitoredSession(session_creator=session_creator) as sess:\n",
    "        for eps in all_eps:\n",
    "            predicted_classes_jpegdefense[eps] = sess.run(predicted_labels, feed_dict={x_input: images})\n",
    "    #         predicted_classes_jpegdefense = sess.run(predicted_labels, feed_dict={x_input: nontargeted_images})\n",
    "            predicted_classes_jpegdefense[eps] = sess.run(predicted_labels, feed_dict={x_input: [adv_images_jpeg[eps]]})\n",
    "\n",
    "            predicted_names_jpegdefense[eps] = (pd.DataFrame({\"CategoryId\": predicted_classes_jpegdefense[eps]})\n",
    "                                      .merge(categories, on=\"CategoryId\")[\"CategoryName\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c323ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(np.concatenate([adv_images_jpeg[0], adv_images_jpeg[0.1], adv_images_jpeg[1]], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c642cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_names_jpegdefense[0])\n",
    "print(predicted_names_jpegdefense[0.01])\n",
    "print(predicted_names_jpegdefense[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90914ec",
   "metadata": {},
   "source": [
    "# PCA whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813ceb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_base_dir            = './demo'\n",
    "denoise_base_dir           = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5830bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_whole(attack_base_dir, denoise_base_dir, 36) # last parameter is number of PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7685a749",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir            = './pca_whole_36/demo/original'\n",
    "output_dir           = './demo2/adversarial'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ab1ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eps = np.append(np.linspace(0, 0.2, 21), 1)\n",
    "all_eps = list(map(lambda x: round(x, 2), all_eps))\n",
    "adv_images_pcawhole = dict()\n",
    "for eps in all_eps:\n",
    "    with tf.Graph().as_default():\n",
    "        # Prepare graph\n",
    "        x_input = tf.placeholder(tf.float32, shape=batch_shape)\n",
    "\n",
    "        model = InceptionModel(num_classes)\n",
    "\n",
    "        fgsm = FastGradientMethod(model)\n",
    "        x_adv = fgsm.generate(x_input, eps=eps, clip_min=-1., clip_max=1.)\n",
    "\n",
    "        # Run computation\n",
    "        saver = tf.train.Saver(slim.get_model_variables())\n",
    "        session_creator = tf.train.ChiefSessionCreator(\n",
    "                                scaffold=tf.train.Scaffold(saver=saver),\n",
    "                                checkpoint_filename_with_path=checkpoint_path)\n",
    "\n",
    "        with tf.train.MonitoredSession(session_creator=session_creator) as sess:\n",
    "            filenames, images = next(load_images(input_dir, batch_shape))\n",
    "            adv_images_pcawhole[eps] = sess.run(x_adv, feed_dict={x_input: images})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cc5db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes_pcawholedefense = dict()\n",
    "predicted_names_pcawholedefense = dict()\n",
    "with tf.Graph().as_default():\n",
    "    x_input = tf.placeholder(tf.float32, shape=batch_shape)\n",
    "\n",
    "    with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "        _, end_points = inception.inception_v3(x_input, num_classes=num_classes, is_training=False)\n",
    "    \n",
    "    predicted_labels = tf.argmax(end_points['Predictions'], 1)\n",
    "    saver = tf.train.Saver(slim.get_model_variables())\n",
    "    session_creator = tf.train.ChiefSessionCreator(\n",
    "                      scaffold=tf.train.Scaffold(saver=saver),\n",
    "                      checkpoint_filename_with_path=checkpoint_path,\n",
    "                      master=tensorflow_master)\n",
    "\n",
    "    with tf.train.MonitoredSession(session_creator=session_creator) as sess:\n",
    "        for eps in all_eps:\n",
    "            predicted_classes_pcawholedefense[eps] = sess.run(predicted_labels, feed_dict={x_input: images})\n",
    "    #         predicted_classes_pcawholedefense = sess.run(predicted_labels, feed_dict={x_input: nontargeted_images})\n",
    "            predicted_classes_pcawholedefense[eps] = sess.run(predicted_labels, feed_dict={x_input: [adv_images_pcawhole[eps]]})\n",
    "\n",
    "            predicted_names_pcawholedefense[eps] = (pd.DataFrame({\"CategoryId\": predicted_classes_pcawholedefense[eps]})\n",
    "                                      .merge(categories, on=\"CategoryId\")[\"CategoryName\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a435d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(np.concatenate([adv_images_pcawhole[0], adv_images_pcawhole[0.1], adv_images_pcawhole[1]], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cb8474",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_names_pcawholedefense[0])\n",
    "print(predicted_names_pcawholedefense[0.01])\n",
    "print(predicted_names_pcawholedefense[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c182c6",
   "metadata": {},
   "source": [
    "# PCA blockwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd114207",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_base_dir            = './demo'\n",
    "denoise_base_dir           = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e36b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_blockwise(attack_base_dir, denoise_base_dir, 13) # last parameter is number of PCs per block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir            = './pca_blockwise_13/demo/original'\n",
    "output_dir           = './demo3/adversarial'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6a907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eps = np.append(np.linspace(0, 0.2, 21), 1)\n",
    "all_eps = list(map(lambda x: round(x, 2), all_eps))\n",
    "adv_images_pcablockwise = dict()\n",
    "for eps in all_eps:\n",
    "    with tf.Graph().as_default():\n",
    "        # Prepare graph\n",
    "        x_input = tf.placeholder(tf.float32, shape=batch_shape)\n",
    "\n",
    "        model = InceptionModel(num_classes)\n",
    "\n",
    "        fgsm = FastGradientMethod(model)\n",
    "        x_adv = fgsm.generate(x_input, eps=eps, clip_min=-1., clip_max=1.)\n",
    "\n",
    "        # Run computation\n",
    "        saver = tf.train.Saver(slim.get_model_variables())\n",
    "        session_creator = tf.train.ChiefSessionCreator(\n",
    "                                scaffold=tf.train.Scaffold(saver=saver),\n",
    "                                checkpoint_filename_with_path=checkpoint_path)\n",
    "\n",
    "        with tf.train.MonitoredSession(session_creator=session_creator) as sess:\n",
    "            filenames, images = next(load_images(input_dir, batch_shape))\n",
    "            adv_images_pcablockwise[eps] = sess.run(x_adv, feed_dict={x_input: images})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e00fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes_pcablockwisedefense = dict()\n",
    "predicted_names_pcablockwisedefense = dict()\n",
    "with tf.Graph().as_default():\n",
    "    x_input = tf.placeholder(tf.float32, shape=batch_shape)\n",
    "\n",
    "    with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "        _, end_points = inception.inception_v3(x_input, num_classes=num_classes, is_training=False)\n",
    "    \n",
    "    predicted_labels = tf.argmax(end_points['Predictions'], 1)\n",
    "    saver = tf.train.Saver(slim.get_model_variables())\n",
    "    session_creator = tf.train.ChiefSessionCreator(\n",
    "                      scaffold=tf.train.Scaffold(saver=saver),\n",
    "                      checkpoint_filename_with_path=checkpoint_path,\n",
    "                      master=tensorflow_master)\n",
    "\n",
    "    with tf.train.MonitoredSession(session_creator=session_creator) as sess:\n",
    "        for eps in all_eps:\n",
    "            predicted_classes_pcablockwisedefense[eps] = sess.run(predicted_labels, feed_dict={x_input: images})\n",
    "    #         predicted_classes_pcablockwisedefense = sess.run(predicted_labels, feed_dict={x_input: nontargeted_images})\n",
    "            predicted_classes_pcablockwisedefense[eps] = sess.run(predicted_labels, feed_dict={x_input: [adv_images_pcablockwise[eps]]})\n",
    "\n",
    "            predicted_names_pcablockwisedefense[eps] = (pd.DataFrame({\"CategoryId\": predicted_classes_pcablockwisedefense[eps]})\n",
    "                                      .merge(categories, on=\"CategoryId\")[\"CategoryName\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f5b826",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(np.concatenate([adv_images_pcablockwise[0], adv_images_pcablockwise[0.1], adv_images_pcablockwise[1]], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae654f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_names_pcablockwisedefense[0])\n",
    "print(predicted_names_pcablockwisedefense[0.01])\n",
    "print(predicted_names_pcablockwisedefense[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dffe598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba90a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddd6e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe77d68c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70a8c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888cf767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8bf28e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b1df50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23181457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18117b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954c723c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5339b4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addddfb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f674462e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd49f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a8efbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89fd7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a08656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae4a4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a95c4bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3eb9613c",
   "metadata": {},
   "source": [
    "# Some old helper funtions that I can't remember if they're still helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8431b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_helper(image_list, imgdir_path, imgdir_denoised, batch_shape, img_fmt):\n",
    "    images = np.zeros(batch_shape)\n",
    "    images_denoised = np.zeros(batch_shape)\n",
    "    filenames = []\n",
    "    idx = 0\n",
    "    batch_size = batch_shape[0]\n",
    "    for filepath in image_list:\n",
    "        with tf.gfile.Open(os.path.join(imgdir_path, filepath), \"rb\") as f:\n",
    "            images[idx, :, :, :] = imread(f, mode='RGB').astype(np.float)*2.0/255.0 - 1.0\n",
    "        if img_fmt == 'jpg':\n",
    "            filepath = filepath.replace('png', img_fmt)\n",
    "        with tf.gfile.Open(os.path.join(imgdir_denoised, filepath), \"rb\") as f:\n",
    "            images_denoised[idx, :, :, :] = imread(f, mode='RGB').astype(np.float)*2.0/255.0 - 1.0\n",
    "        if img_fmt == 'jpg':\n",
    "            filepath = filepath.replace(img_fmt, 'png')\n",
    "        filenames.append(os.path.basename(filepath))\n",
    "        idx += 1\n",
    "        if idx == batch_size:\n",
    "            yield filenames, images_denoised, images\n",
    "            filenames = []\n",
    "            images = np.zeros(batch_shape)\n",
    "            images_denoised = np.zeros(batch_shape)\n",
    "            idx = 0\n",
    "    if idx > 0:\n",
    "        yield filenames, images_denoised, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2d1c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_list(benign_dir, random_seed, subset_num):\n",
    "    images_whole      = [f for f in os.listdir(benign_dir) if os.path.isfile(os.path.join(benign_dir, f))]\n",
    "    images_whole      = sorted(images_whole)\n",
    "\n",
    "    if random_seed != None:\n",
    "        random.seed(random_seed)\n",
    "        # generate random indices to subset\n",
    "        subset_ids  = random.sample(range(len(images_whole)), subset_num)  \n",
    "    else:\n",
    "        subset_ids  = range(subset_num)\n",
    "\n",
    "    image_list = [images_whole[i] for i in subset_ids]\n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23226c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(images, filenames, output_dir):\n",
    "    for i, filename in enumerate(filenames):\n",
    "        img = np.uint8(((images[i, :, :, :] + 1.0) * 0.5) * 255.0)\n",
    "        imsave(output_dir+filename, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e2ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(input_dir, batch_shape):\n",
    "    images = np.zeros(batch_shape)\n",
    "    filenames = []\n",
    "    idx = 0\n",
    "    batch_size = batch_shape[0]\n",
    "    for filepath in sorted(tf.gfile.Glob(os.path.join(input_dir, '*.png'))):\n",
    "        with tf.gfile.Open(filepath, \"rb\") as f:\n",
    "            images[idx, :, :, :] = imread(f, mode='RGB').astype(np.float)*2.0/255.0 - 1.0\n",
    "        filenames.append(os.path.basename(filepath))\n",
    "        idx += 1\n",
    "        if idx == batch_size:\n",
    "            yield filenames, images\n",
    "            filenames = []\n",
    "            images = np.zeros(batch_shape)\n",
    "            idx = 0\n",
    "    if idx > 0:\n",
    "        yield filenames, images\n",
    "\n",
    "def show_image(a, fmt='png'):\n",
    "    a = np.uint8((a+1.0)/2.0*255.0)\n",
    "    f = BytesIO()\n",
    "    Image.fromarray(a).save(f, fmt)\n",
    "    IPython.display.display(IPython.display.Image(data=f.getvalue()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d19cd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
